{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshiho0/AI-for-transportation/blob/main/Exercise7_Neural_Networks_2_ipynb_ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jwxWYSMMweC"
      },
      "source": [
        "# **Neural Network**\n",
        "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\n",
        "\n",
        "Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbJz5TA3JyBC"
      },
      "source": [
        "# **TASK 1: Develop the neural network model for predicting the count of rental bikes.​**\n",
        "As experienced in regression exercise, the regression models did not perform well on the task of the count of rental bikes prediction. We look into the deep learing and This task will use the simple 2-layers fully connected neural network model as the example and guide you through the step-by-step process of the whole process of the model development.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGcXA3loalhv"
      },
      "source": [
        "## Load and prepare the data\n",
        "Start by loading the dataset and shaping it so that it's suitable for use in machine learning. This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SAX-uM0-tltd",
        "outputId": "1804bceb-bf29-4b31-9b34-cd9ece4a5318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
              "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
              "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
              "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
              "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
              "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
              "5        6  2011-01-01       1   0     1   5        0        6           0   \n",
              "6        7  2011-01-01       1   0     1   6        0        6           0   \n",
              "7        8  2011-01-01       1   0     1   7        0        6           0   \n",
              "8        9  2011-01-01       1   0     1   8        0        6           0   \n",
              "9       10  2011-01-01       1   0     1   9        0        6           0   \n",
              "\n",
              "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
              "0           1  0.24  0.2879  0.81     0.0000       3          13   16  \n",
              "1           1  0.22  0.2727  0.80     0.0000       8          32   40  \n",
              "2           1  0.22  0.2727  0.80     0.0000       5          27   32  \n",
              "3           1  0.24  0.2879  0.75     0.0000       3          10   13  \n",
              "4           1  0.24  0.2879  0.75     0.0000       0           1    1  \n",
              "5           2  0.24  0.2576  0.75     0.0896       0           1    1  \n",
              "6           1  0.22  0.2727  0.80     0.0000       2           0    2  \n",
              "7           1  0.20  0.2576  0.86     0.0000       1           2    3  \n",
              "8           1  0.24  0.2879  0.75     0.0000       1           7    8  \n",
              "9           1  0.32  0.3485  0.76     0.0000       8           6   14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b67036c2-b25f-4cb7-a1a3-75b5f0b49816\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0896</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.3485</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b67036c2-b25f-4cb7-a1a3-75b5f0b49816')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b67036c2-b25f-4cb7-a1a3-75b5f0b49816 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b67036c2-b25f-4cb7-a1a3-75b5f0b49816');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-96711c7b-953a-472e-a31e-8bf70cada0e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96711c7b-953a-472e-a31e-8bf70cada0e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-96711c7b-953a-472e-a31e-8bf70cada0e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17379,\n  \"fields\": [\n    {\n      \"column\": \"instant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5017,\n        \"min\": 1,\n        \"max\": 17379,\n        \"num_unique_values\": 17379,\n        \"samples\": [\n          12831,\n          8689,\n          7092\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dteday\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 731,\n        \"samples\": [\n          \"2012-12-04\",\n          \"2011-02-03\",\n          \"2011-10-28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mnth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workingday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weathersit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19255612124972407,\n        \"min\": 0.02,\n        \"max\": 1.0,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.16,\n          0.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17185021563536587,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.7879,\n          0.9242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1929298340629125,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.29,\n          0.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"windspeed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12234022857279413,\n        \"min\": 0.0,\n        \"max\": 0.8507,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.8507,\n          0.4925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"casual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 0,\n        \"max\": 367,\n        \"num_unique_values\": 322,\n        \"samples\": [\n          201,\n          171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"registered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": 0,\n        \"max\": 886,\n        \"num_unique_values\": 776,\n        \"samples\": [\n          342,\n          744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 181,\n        \"min\": 1,\n        \"max\": 977,\n        \"num_unique_values\": 869,\n        \"samples\": [\n          594,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sympy.printing.tensorflow import tensorflow\n",
        "\n",
        "# Define the URL from which to fetch the CSV data.\n",
        "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_7_Neural_networks/Exercise7BikeSharing.csv'\n",
        "\n",
        "# Use pandas to read the CSV data from the specified URL and store it in a DataFrame 'df'.\n",
        "#df = pd.read_csv(url)\n",
        "# Display the first 10 rows of the DataFrame 'df'.\n",
        "df = pd.read_csv('Exercise7BikeSharing.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0luS_xvkX_0"
      },
      "source": [
        "How many rows and columns does the dataset contain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oqOWyEvqF7B",
        "outputId": "eb4bdc8a-4471-4f4c-ec03-8d3ca7954207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17379, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBtY9y0aqWnh"
      },
      "source": [
        "Are any of the columns missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZbnejxAwLBC",
        "outputId": "97de2987-d2e9-4d21-b890-f104715e9fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17379 entries, 0 to 17378\n",
            "Data columns (total 17 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   instant     17379 non-null  int64  \n",
            " 1   dteday      17379 non-null  object \n",
            " 2   season      17379 non-null  int64  \n",
            " 3   yr          17379 non-null  int64  \n",
            " 4   mnth        17379 non-null  int64  \n",
            " 5   hr          17379 non-null  int64  \n",
            " 6   holiday     17379 non-null  int64  \n",
            " 7   weekday     17379 non-null  int64  \n",
            " 8   workingday  17379 non-null  int64  \n",
            " 9   weathersit  17379 non-null  int64  \n",
            " 10  temp        17379 non-null  float64\n",
            " 11  atemp       17379 non-null  float64\n",
            " 12  hum         17379 non-null  float64\n",
            " 13  windspeed   17379 non-null  float64\n",
            " 14  casual      17379 non-null  int64  \n",
            " 15  registered  17379 non-null  int64  \n",
            " 16  cnt         17379 non-null  int64  \n",
            "dtypes: float64(4), int64(12), object(1)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBzn2CezpJiB"
      },
      "source": [
        "## Feature engineering\n",
        "- Target: `cnt` (count of total rental bikes including both casual and registered)\n",
        "- Predictors: weather (`temp`, `atemp`, `hum`, `windspeed`, `weathersit`), calendar (`hr`, `weekday`, `workingday`, `holiday`, `season`), and `yr`.\n",
        "- We keep it simple; you can expand features (e.g., interactions) later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UjiQ_pe6pIcC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "target = 'cnt'\n",
        "features = [\n",
        "    'temp','atemp','hum','windspeed','weathersit',\n",
        "    'hr','weekday','workingday','holiday','season','yr'\n",
        "]\n",
        "\n",
        "X = df[features].copy()\n",
        "X['hr_workingday'] = df['hr'] * df['workingday']\n",
        "X['weathersit_windspeed'] = df['windspeed'] * df['weathersit']\n",
        "X['weathersit_season'] = df['season'] * df['weathersit']\n",
        "y = df[target].astype(float)\n",
        "\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features (important for NN)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKhwhwhEkvSz"
      },
      "source": [
        "**(Optional) quick baseline (Linear Regression)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G0qaCW4wWHv",
        "outputId": "ed856d05-6653-4127-fb46-96b06720c76b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LR_RMSE': np.float64(138.9062209264245), 'LR_MAE': 104.32926533779367, 'LR_R2': 0.39066200634361614}\n"
          ]
        }
      ],
      "source": [
        "# A super-fast baseline, just for context\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "# rmse_lr = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "print({\"LR_RMSE\": rmse_lr, \"LR_MAE\": mae_lr, \"LR_R2\": r2_lr})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlqm-Kptw7M3"
      },
      "source": [
        "## Create a neural network model\n",
        "Now it's time build a neural network and train it with the data prepared in the previous exercise. We'll try neural network first and use cross-validation its meaasure accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2YhQgWEgOBd",
        "outputId": "408eef4d-d0e7-4153-f554-bd619195cc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "U1nmDlwNoEiz",
        "outputId": "9116ba01-1de6-4e12-af7f-24d7bedfc8d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,657\u001b[0m (10.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,657</span> (10.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,657\u001b[0m (10.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,657</span> (10.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create a Sequential model, which is a linear stack of layers.\n",
        "model = Sequential()\n",
        "# Add a Dense layer with 32 units, ReLU activation, and an input dimension of 11.\n",
        "model.add(Dense(32, activation='relu', input_dim=14))\n",
        "# Add another Dense layer with 64 units and ReLU activation.\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# Add a final Dense layer with 1 unit (typically used for regression tasks).\n",
        "model.add(Dense(1))\n",
        "# Compile the model with the Adam optimizer, Mean Absolute Error (MAE) loss function,\n",
        "# and MAE metric to be used during training.\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "# Display a summary of the model architecture, including the number of parameters.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I07TdY4jtw2k"
      },
      "source": [
        "## Training and prediction\n",
        "We split the dataset into a training and a test dataset. Then, we fit the neural network model with the training dataset and predict the values for the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjB13IIZlxbQ",
        "outputId": "442d8548-85bb-480e-bc2f-db7d4800f661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 170.4708 - mae: 170.4708 - val_loss: 100.7921 - val_mae: 100.7921\n",
            "Epoch 2/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 101.5500 - mae: 101.5500 - val_loss: 98.2479 - val_mae: 98.2479\n",
            "Epoch 3/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.9154 - mae: 98.9154 - val_loss: 96.9138 - val_mae: 96.9138\n",
            "Epoch 4/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.2651 - mae: 96.2651 - val_loss: 95.6248 - val_mae: 95.6248\n",
            "Epoch 5/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.9579 - mae: 95.9579 - val_loss: 94.2607 - val_mae: 94.2607\n",
            "Epoch 6/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.2635 - mae: 94.2635 - val_loss: 92.9301 - val_mae: 92.9301\n",
            "Epoch 7/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.8871 - mae: 92.8871 - val_loss: 91.7523 - val_mae: 91.7523\n",
            "Epoch 8/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.2793 - mae: 91.2793 - val_loss: 90.5741 - val_mae: 90.5741\n",
            "Epoch 9/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 89.4147 - mae: 89.4147 - val_loss: 89.6163 - val_mae: 89.6163\n",
            "Epoch 10/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88.5029 - mae: 88.5029 - val_loss: 88.0748 - val_mae: 88.0748\n",
            "Epoch 11/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88.6083 - mae: 88.6083 - val_loss: 86.6123 - val_mae: 86.6123\n",
            "Epoch 12/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86.2602 - mae: 86.2602 - val_loss: 85.1460 - val_mae: 85.1460\n",
            "Epoch 13/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 84.4510 - mae: 84.4510 - val_loss: 83.6296 - val_mae: 83.6296\n",
            "Epoch 14/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 83.0322 - mae: 83.0322 - val_loss: 81.9564 - val_mae: 81.9564\n",
            "Epoch 15/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 81.4059 - mae: 81.4059 - val_loss: 79.9585 - val_mae: 79.9585\n",
            "Epoch 16/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 78.0805 - mae: 78.0805 - val_loss: 77.7833 - val_mae: 77.7833\n",
            "Epoch 17/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 76.5616 - mae: 76.5616 - val_loss: 75.1259 - val_mae: 75.1259\n",
            "Epoch 18/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.2352 - mae: 73.2352 - val_loss: 72.8153 - val_mae: 72.8153\n",
            "Epoch 19/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.2252 - mae: 70.2252 - val_loss: 70.2628 - val_mae: 70.2628\n",
            "Epoch 20/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 68.0859 - mae: 68.0859 - val_loss: 68.6271 - val_mae: 68.6271\n",
            "Epoch 21/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 66.0930 - mae: 66.0930 - val_loss: 66.9992 - val_mae: 66.9992\n",
            "Epoch 22/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65.2248 - mae: 65.2248 - val_loss: 65.9926 - val_mae: 65.9926\n",
            "Epoch 23/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64.1935 - mae: 64.1935 - val_loss: 64.8381 - val_mae: 64.8381\n",
            "Epoch 24/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 62.7311 - mae: 62.7311 - val_loss: 63.4366 - val_mae: 63.4366\n",
            "Epoch 25/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 60.2385 - mae: 60.2385 - val_loss: 62.6612 - val_mae: 62.6612\n",
            "Epoch 26/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 61.2878 - mae: 61.2878 - val_loss: 61.7300 - val_mae: 61.7300\n",
            "Epoch 27/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 59.6973 - mae: 59.6973 - val_loss: 61.0099 - val_mae: 61.0099\n",
            "Epoch 28/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58.7903 - mae: 58.7903 - val_loss: 60.9230 - val_mae: 60.9230\n",
            "Epoch 29/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56.4824 - mae: 56.4824 - val_loss: 59.3696 - val_mae: 59.3696\n",
            "Epoch 30/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 56.1674 - mae: 56.1674 - val_loss: 58.7162 - val_mae: 58.7162\n",
            "Epoch 31/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56.1199 - mae: 56.1199 - val_loss: 57.4007 - val_mae: 57.4007\n",
            "Epoch 32/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55.3057 - mae: 55.3057 - val_loss: 56.9481 - val_mae: 56.9481\n",
            "Epoch 33/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55.7393 - mae: 55.7393 - val_loss: 56.2578 - val_mae: 56.2578\n",
            "Epoch 34/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53.1077 - mae: 53.1077 - val_loss: 55.1415 - val_mae: 55.1415\n",
            "Epoch 35/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54.0371 - mae: 54.0371 - val_loss: 55.1673 - val_mae: 55.1673\n",
            "Epoch 36/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52.0334 - mae: 52.0334 - val_loss: 53.9461 - val_mae: 53.9461\n",
            "Epoch 37/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 52.4509 - mae: 52.4509 - val_loss: 53.4904 - val_mae: 53.4904\n",
            "Epoch 38/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 51.0229 - mae: 51.0229 - val_loss: 53.2954 - val_mae: 53.2954\n",
            "Epoch 39/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 50.6245 - mae: 50.6245 - val_loss: 52.6333 - val_mae: 52.6333\n",
            "Epoch 40/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50.4499 - mae: 50.4499 - val_loss: 51.9327 - val_mae: 51.9327\n",
            "Epoch 41/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49.0876 - mae: 49.0876 - val_loss: 51.2043 - val_mae: 51.2043\n",
            "Epoch 42/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49.9172 - mae: 49.9172 - val_loss: 51.0109 - val_mae: 51.0109\n",
            "Epoch 43/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49.5759 - mae: 49.5759 - val_loss: 50.5931 - val_mae: 50.5931\n",
            "Epoch 44/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48.5998 - mae: 48.5998 - val_loss: 50.0071 - val_mae: 50.0071\n",
            "Epoch 45/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48.0178 - mae: 48.0178 - val_loss: 49.6186 - val_mae: 49.6186\n",
            "Epoch 46/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48.4283 - mae: 48.4283 - val_loss: 48.9419 - val_mae: 48.9419\n",
            "Epoch 47/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 47.1462 - mae: 47.1462 - val_loss: 48.1339 - val_mae: 48.1339\n",
            "Epoch 48/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 46.4473 - mae: 46.4473 - val_loss: 48.0000 - val_mae: 48.0000\n",
            "Epoch 49/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48.0917 - mae: 48.0917 - val_loss: 47.3135 - val_mae: 47.3135\n",
            "Epoch 50/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45.7204 - mae: 45.7204 - val_loss: 47.7792 - val_mae: 47.7792\n",
            "Epoch 51/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 45.1048 - mae: 45.1048 - val_loss: 46.7424 - val_mae: 46.7424\n",
            "Epoch 52/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 44.9284 - mae: 44.9284 - val_loss: 45.9978 - val_mae: 45.9978\n",
            "Epoch 53/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43.8974 - mae: 43.8974 - val_loss: 46.5804 - val_mae: 46.5804\n",
            "Epoch 54/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 45.1008 - mae: 45.1008 - val_loss: 45.2942 - val_mae: 45.2942\n",
            "Epoch 55/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43.6817 - mae: 43.6817 - val_loss: 44.5716 - val_mae: 44.5716\n",
            "Epoch 56/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43.1111 - mae: 43.1111 - val_loss: 44.3967 - val_mae: 44.3967\n",
            "Epoch 57/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42.2609 - mae: 42.2609 - val_loss: 44.2646 - val_mae: 44.2646\n",
            "Epoch 58/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41.8768 - mae: 41.8768 - val_loss: 43.7782 - val_mae: 43.7782\n",
            "Epoch 59/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42.3327 - mae: 42.3327 - val_loss: 43.2605 - val_mae: 43.2605\n",
            "Epoch 60/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 41.3692 - mae: 41.3692 - val_loss: 42.7627 - val_mae: 42.7627\n",
            "Epoch 61/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42.7069 - mae: 42.7069 - val_loss: 42.6627 - val_mae: 42.6627\n",
            "Epoch 62/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.5149 - mae: 40.5149 - val_loss: 42.3889 - val_mae: 42.3889\n",
            "Epoch 63/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.1804 - mae: 40.1804 - val_loss: 42.3297 - val_mae: 42.3297\n",
            "Epoch 64/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 41.0248 - mae: 41.0248 - val_loss: 41.6927 - val_mae: 41.6927\n",
            "Epoch 65/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 40.4534 - mae: 40.4534 - val_loss: 41.2566 - val_mae: 41.2566\n",
            "Epoch 66/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 40.6103 - mae: 40.6103 - val_loss: 41.1999 - val_mae: 41.1999\n",
            "Epoch 67/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.4055 - mae: 40.4055 - val_loss: 41.1518 - val_mae: 41.1518\n",
            "Epoch 68/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.5352 - mae: 39.5352 - val_loss: 40.6812 - val_mae: 40.6812\n",
            "Epoch 69/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.2186 - mae: 39.2186 - val_loss: 40.5733 - val_mae: 40.5733\n",
            "Epoch 70/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.5740 - mae: 39.5740 - val_loss: 40.3310 - val_mae: 40.3310\n",
            "Epoch 71/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.0017 - mae: 39.0017 - val_loss: 40.1085 - val_mae: 40.1085\n",
            "Epoch 72/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 38.6845 - mae: 38.6845 - val_loss: 39.6484 - val_mae: 39.6484\n",
            "Epoch 73/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 37.7882 - mae: 37.7882 - val_loss: 40.0810 - val_mae: 40.0810\n",
            "Epoch 74/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.1212 - mae: 38.1212 - val_loss: 39.9325 - val_mae: 39.9325\n",
            "Epoch 75/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 38.1634 - mae: 38.1634 - val_loss: 39.6754 - val_mae: 39.6754\n",
            "Epoch 76/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 37.4839 - mae: 37.4839 - val_loss: 39.3266 - val_mae: 39.3266\n",
            "Epoch 77/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 37.4351 - mae: 37.4351 - val_loss: 39.0346 - val_mae: 39.0346\n",
            "Epoch 78/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37.7708 - mae: 37.7708 - val_loss: 39.9064 - val_mae: 39.9064\n",
            "Epoch 79/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37.2138 - mae: 37.2138 - val_loss: 39.1158 - val_mae: 39.1158\n",
            "Epoch 80/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36.6525 - mae: 36.6525 - val_loss: 38.6588 - val_mae: 38.6588\n",
            "Epoch 81/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 36.9316 - mae: 36.9316 - val_loss: 38.4855 - val_mae: 38.4855\n",
            "Epoch 82/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 36.5542 - mae: 36.5542 - val_loss: 38.1843 - val_mae: 38.1843\n",
            "Epoch 83/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 36.9029 - mae: 36.9029 - val_loss: 38.7519 - val_mae: 38.7519\n",
            "Epoch 84/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 36.5626 - mae: 36.5626 - val_loss: 38.6380 - val_mae: 38.6380\n",
            "Epoch 85/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36.0469 - mae: 36.0469 - val_loss: 38.6542 - val_mae: 38.6542\n",
            "Epoch 86/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36.7142 - mae: 36.7142 - val_loss: 37.8556 - val_mae: 37.8556\n",
            "Epoch 87/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.6993 - mae: 35.6993 - val_loss: 37.7948 - val_mae: 37.7948\n",
            "Epoch 88/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 36.2428 - mae: 36.2428 - val_loss: 37.3630 - val_mae: 37.3630\n",
            "Epoch 89/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 35.8790 - mae: 35.8790 - val_loss: 37.5152 - val_mae: 37.5152\n",
            "Epoch 90/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 35.6672 - mae: 35.6672 - val_loss: 37.2167 - val_mae: 37.2167\n",
            "Epoch 91/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.7765 - mae: 34.7765 - val_loss: 37.1189 - val_mae: 37.1189\n",
            "Epoch 92/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.4978 - mae: 35.4978 - val_loss: 37.2250 - val_mae: 37.2250\n",
            "Epoch 93/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.7388 - mae: 34.7388 - val_loss: 36.9686 - val_mae: 36.9686\n",
            "Epoch 94/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.6602 - mae: 35.6602 - val_loss: 37.0092 - val_mae: 37.0092\n",
            "Epoch 95/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.9018 - mae: 34.9018 - val_loss: 37.0876 - val_mae: 37.0876\n",
            "Epoch 96/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.6302 - mae: 35.6302 - val_loss: 36.5968 - val_mae: 36.5968\n",
            "Epoch 97/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.6890 - mae: 34.6890 - val_loss: 36.8111 - val_mae: 36.8111\n",
            "Epoch 98/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.9444 - mae: 34.9444 - val_loss: 36.6946 - val_mae: 36.6946\n",
            "Epoch 99/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.6079 - mae: 35.6079 - val_loss: 36.6001 - val_mae: 36.6001\n",
            "Epoch 100/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.2333 - mae: 34.2333 - val_loss: 36.2827 - val_mae: 36.2827\n",
            "Epoch 101/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.2162 - mae: 34.2162 - val_loss: 36.4576 - val_mae: 36.4576\n",
            "Epoch 102/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 34.9407 - mae: 34.9407 - val_loss: 36.2828 - val_mae: 36.2828\n",
            "Epoch 103/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 35.0703 - mae: 35.0703 - val_loss: 36.1098 - val_mae: 36.1098\n",
            "Epoch 104/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.0896 - mae: 35.0896 - val_loss: 35.7651 - val_mae: 35.7651\n",
            "Epoch 105/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.6061 - mae: 34.6061 - val_loss: 35.8696 - val_mae: 35.8696\n",
            "Epoch 106/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.0572 - mae: 34.0572 - val_loss: 36.1138 - val_mae: 36.1138\n",
            "Epoch 107/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.0741 - mae: 34.0741 - val_loss: 36.1692 - val_mae: 36.1692\n",
            "Epoch 108/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.0374 - mae: 34.0374 - val_loss: 35.5524 - val_mae: 35.5524\n",
            "Epoch 109/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.7118 - mae: 34.7118 - val_loss: 36.1213 - val_mae: 36.1213\n",
            "Epoch 110/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.2041 - mae: 33.2041 - val_loss: 35.7372 - val_mae: 35.7372\n",
            "Epoch 111/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.4815 - mae: 34.4815 - val_loss: 35.6053 - val_mae: 35.6053\n",
            "Epoch 112/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.3302 - mae: 33.3302 - val_loss: 35.5174 - val_mae: 35.5174\n",
            "Epoch 113/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.4589 - mae: 33.4589 - val_loss: 35.9291 - val_mae: 35.9291\n",
            "Epoch 114/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.2047 - mae: 33.2047 - val_loss: 35.3599 - val_mae: 35.3599\n",
            "Epoch 115/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 34.3095 - mae: 34.3095 - val_loss: 34.8811 - val_mae: 34.8811\n",
            "Epoch 116/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 33.8109 - mae: 33.8109 - val_loss: 35.7330 - val_mae: 35.7330\n",
            "Epoch 117/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 33.0704 - mae: 33.0704 - val_loss: 34.8218 - val_mae: 34.8218\n",
            "Epoch 118/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.0279 - mae: 34.0279 - val_loss: 35.0174 - val_mae: 35.0174\n",
            "Epoch 119/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.8548 - mae: 32.8548 - val_loss: 34.7433 - val_mae: 34.7433\n",
            "Epoch 120/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.8389 - mae: 32.8389 - val_loss: 35.7683 - val_mae: 35.7683\n",
            "Epoch 121/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.1442 - mae: 33.1442 - val_loss: 35.1665 - val_mae: 35.1665\n",
            "Epoch 122/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.4772 - mae: 33.4772 - val_loss: 34.8872 - val_mae: 34.8872\n",
            "Epoch 123/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.2980 - mae: 33.2980 - val_loss: 34.5847 - val_mae: 34.5847\n",
            "Epoch 124/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.7920 - mae: 33.7920 - val_loss: 34.9506 - val_mae: 34.9506\n",
            "Epoch 125/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.8556 - mae: 33.8556 - val_loss: 34.4752 - val_mae: 34.4752\n",
            "Epoch 126/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.5841 - mae: 33.5841 - val_loss: 34.9783 - val_mae: 34.9783\n",
            "Epoch 127/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.5302 - mae: 32.5302 - val_loss: 34.7609 - val_mae: 34.7609\n",
            "Epoch 128/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 33.1369 - mae: 33.1369 - val_loss: 34.6961 - val_mae: 34.6961\n",
            "Epoch 129/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 32.7490 - mae: 32.7490 - val_loss: 34.1703 - val_mae: 34.1703\n",
            "Epoch 130/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.3664 - mae: 32.3664 - val_loss: 34.0860 - val_mae: 34.0860\n",
            "Epoch 131/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.2945 - mae: 32.2945 - val_loss: 34.3031 - val_mae: 34.3031\n",
            "Epoch 132/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.0225 - mae: 32.0225 - val_loss: 34.5898 - val_mae: 34.5898\n",
            "Epoch 133/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.4319 - mae: 32.4319 - val_loss: 34.1081 - val_mae: 34.1081\n",
            "Epoch 134/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 32.0447 - mae: 32.0447 - val_loss: 33.9015 - val_mae: 33.9015\n",
            "Epoch 135/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31.6869 - mae: 31.6869 - val_loss: 34.2277 - val_mae: 34.2277\n",
            "Epoch 136/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.1806 - mae: 33.1806 - val_loss: 34.2284 - val_mae: 34.2284\n",
            "Epoch 137/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.2634 - mae: 32.2634 - val_loss: 34.1761 - val_mae: 34.1761\n",
            "Epoch 138/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.1183 - mae: 33.1183 - val_loss: 33.9712 - val_mae: 33.9712\n",
            "Epoch 139/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31.8271 - mae: 31.8271 - val_loss: 34.2335 - val_mae: 34.2335\n",
            "Epoch 140/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 31.8040 - mae: 31.8040 - val_loss: 33.9393 - val_mae: 33.9393\n",
            "Epoch 141/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.3501 - mae: 32.3501 - val_loss: 33.9588 - val_mae: 33.9588\n",
            "Epoch 142/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 32.3734 - mae: 32.3734 - val_loss: 33.6702 - val_mae: 33.6702\n",
            "Epoch 143/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.1382 - mae: 32.1382 - val_loss: 34.2294 - val_mae: 34.2294\n",
            "Epoch 144/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.5173 - mae: 32.5173 - val_loss: 33.6748 - val_mae: 33.6748\n",
            "Epoch 145/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.1142 - mae: 32.1142 - val_loss: 33.8088 - val_mae: 33.8088\n",
            "Epoch 146/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.4180 - mae: 32.4180 - val_loss: 33.6022 - val_mae: 33.6022\n",
            "Epoch 147/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 32.4334 - mae: 32.4334 - val_loss: 33.6323 - val_mae: 33.6323\n",
            "Epoch 148/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.2031 - mae: 31.2031 - val_loss: 33.6395 - val_mae: 33.6395\n",
            "Epoch 149/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.2714 - mae: 31.2714 - val_loss: 34.0085 - val_mae: 34.0085\n",
            "Epoch 150/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.3118 - mae: 32.3118 - val_loss: 33.7278 - val_mae: 33.7278\n",
            "Epoch 151/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.5938 - mae: 31.5938 - val_loss: 33.7631 - val_mae: 33.7631\n",
            "Epoch 152/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.7535 - mae: 31.7535 - val_loss: 33.6884 - val_mae: 33.6884\n",
            "Epoch 153/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 32.0166 - mae: 32.0166 - val_loss: 34.0651 - val_mae: 34.0651\n",
            "Epoch 154/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.8877 - mae: 31.8877 - val_loss: 33.8725 - val_mae: 33.8725\n",
            "Epoch 155/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.7370 - mae: 31.7370 - val_loss: 33.3237 - val_mae: 33.3237\n",
            "Epoch 156/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.4886 - mae: 31.4886 - val_loss: 33.5387 - val_mae: 33.5387\n",
            "Epoch 157/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.1551 - mae: 31.1551 - val_loss: 33.2554 - val_mae: 33.2554\n",
            "Epoch 158/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.3232 - mae: 31.3232 - val_loss: 33.3909 - val_mae: 33.3909\n",
            "Epoch 159/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.9854 - mae: 31.9854 - val_loss: 33.8222 - val_mae: 33.8222\n",
            "Epoch 160/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.1378 - mae: 32.1378 - val_loss: 32.8258 - val_mae: 32.8258\n",
            "Epoch 161/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.5820 - mae: 31.5820 - val_loss: 33.6654 - val_mae: 33.6654\n",
            "Epoch 162/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.9035 - mae: 31.9035 - val_loss: 34.3080 - val_mae: 34.3080\n",
            "Epoch 163/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.7610 - mae: 31.7610 - val_loss: 33.0442 - val_mae: 33.0442\n",
            "Epoch 164/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.1899 - mae: 31.1899 - val_loss: 32.9688 - val_mae: 32.9688\n",
            "Epoch 165/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.6775 - mae: 31.6775 - val_loss: 33.2764 - val_mae: 33.2764\n",
            "Epoch 166/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31.8857 - mae: 31.8857 - val_loss: 32.8671 - val_mae: 32.8671\n",
            "Epoch 167/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 31.4392 - mae: 31.4392 - val_loss: 34.3100 - val_mae: 34.3100\n",
            "Epoch 168/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.7886 - mae: 31.7886 - val_loss: 33.0013 - val_mae: 33.0013\n",
            "Epoch 169/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.8021 - mae: 31.8021 - val_loss: 33.8476 - val_mae: 33.8476\n",
            "Epoch 170/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.4625 - mae: 30.4625 - val_loss: 33.3458 - val_mae: 33.3458\n",
            "Epoch 171/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.7963 - mae: 31.7963 - val_loss: 32.6200 - val_mae: 32.6200\n",
            "Epoch 172/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.6990 - mae: 30.6990 - val_loss: 32.8959 - val_mae: 32.8959\n",
            "Epoch 173/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.2013 - mae: 31.2013 - val_loss: 33.0279 - val_mae: 33.0279\n",
            "Epoch 174/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.1330 - mae: 31.1330 - val_loss: 33.0962 - val_mae: 33.0962\n",
            "Epoch 175/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.1106 - mae: 31.1106 - val_loss: 32.7808 - val_mae: 32.7808\n",
            "Epoch 176/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.2157 - mae: 31.2157 - val_loss: 32.8993 - val_mae: 32.8993\n",
            "Epoch 177/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 30.8425 - mae: 30.8425 - val_loss: 32.9965 - val_mae: 32.9965\n",
            "Epoch 178/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.8261 - mae: 30.8261 - val_loss: 33.1426 - val_mae: 33.1426\n",
            "Epoch 179/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30.5823 - mae: 30.5823 - val_loss: 32.8763 - val_mae: 32.8763\n",
            "Epoch 180/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30.9885 - mae: 30.9885 - val_loss: 32.9664 - val_mae: 32.9664\n",
            "Epoch 181/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30.4994 - mae: 30.4994 - val_loss: 33.1352 - val_mae: 33.1352\n",
            "Epoch 182/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.2606 - mae: 31.2606 - val_loss: 33.3149 - val_mae: 33.3149\n",
            "Epoch 183/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30.5950 - mae: 30.5950 - val_loss: 32.4659 - val_mae: 32.4659\n",
            "Epoch 184/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.5562 - mae: 31.5562 - val_loss: 32.4866 - val_mae: 32.4866\n",
            "Epoch 185/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.9870 - mae: 30.9870 - val_loss: 32.6172 - val_mae: 32.6172\n",
            "Epoch 186/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30.6945 - mae: 30.6945 - val_loss: 32.6882 - val_mae: 32.6882\n",
            "Epoch 187/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.4164 - mae: 31.4164 - val_loss: 32.7280 - val_mae: 32.7280\n",
            "Epoch 188/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.9671 - mae: 30.9671 - val_loss: 33.3041 - val_mae: 33.3041\n",
            "Epoch 189/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 30.9742 - mae: 30.9742 - val_loss: 32.7259 - val_mae: 32.7259\n",
            "Epoch 190/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 29.9800 - mae: 29.9800 - val_loss: 32.6731 - val_mae: 32.6731\n",
            "Epoch 191/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.4893 - mae: 30.4893 - val_loss: 33.1151 - val_mae: 33.1151\n",
            "Epoch 192/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.5262 - mae: 30.5262 - val_loss: 32.6974 - val_mae: 32.6974\n",
            "Epoch 193/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 31.7077 - mae: 31.7077 - val_loss: 32.6092 - val_mae: 32.6092\n",
            "Epoch 194/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.4202 - mae: 30.4202 - val_loss: 32.5553 - val_mae: 32.5553\n",
            "Epoch 195/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.8955 - mae: 30.8955 - val_loss: 32.4732 - val_mae: 32.4732\n",
            "Epoch 196/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.8220 - mae: 30.8220 - val_loss: 32.6166 - val_mae: 32.6166\n",
            "Epoch 197/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.1576 - mae: 31.1576 - val_loss: 32.4503 - val_mae: 32.4503\n",
            "Epoch 198/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 30.9963 - mae: 30.9963 - val_loss: 33.2948 - val_mae: 33.2948\n",
            "Epoch 199/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.6766 - mae: 30.6766 - val_loss: 32.2599 - val_mae: 32.2599\n",
            "Epoch 200/200\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 30.9797 - mae: 30.9797 - val_loss: 32.5659 - val_mae: 32.5659\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Fit the model to the training data, specifying validation split, epochs, and batch size.\n",
        "hist = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=200, batch_size=32)\n",
        "# Set the style of the plots using Seaborn.\n",
        "sns.set()\n",
        "# Extract the training and validation Mean Absolute Error (MAE) from the training history.\n",
        "err = hist.history['mae']\n",
        "val_err = hist.history['val_mae']\n",
        "# Define the number of epochs.\n",
        "epochs = range(1, len(err) + 1)\n",
        "# Plot the Training MAE and Validation MAE over epochs.\n",
        "plt.plot(epochs, err, '-', label='Training MAE')\n",
        "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
        "plt.title('Training and Validation MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.legend(loc='upper right')\n",
        "plt.plot()\n",
        "# Use the trained model to predict on the test data.\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCgwHsqGvXKo"
      },
      "source": [
        "## Evaluate the model\n",
        "You can evaluate the model's performance using various metrics, such as Mean Absolute Error (MAE), Mean Squared Error (MSE), or R-squared (R2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li-GWBXSn9B2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqPg05l1vf59",
        "outputId": "6c25ed7d-fbbd-4146-d5f7-6b23e149ec30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error of NN: 32.13415938477762\n",
            "Root Mean Squared Error of NN: 51.44573386003852\n",
            "R-squared of NN: 0.9164178382438765\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate the Mean Absolute Error (MAE) between the true and predicted values.\n",
        "mae_nn = mean_absolute_error(y_test, y_pred)\n",
        "# Calculate the Root Mean Squared Error (RMSE) between the true and predicted values.\n",
        "mse_nn = mean_squared_error(y_test, y_pred)\n",
        "# rmse_nn = mean_squared_error(y_test, y_pred, squared=False)\n",
        "rmse_nn = np.sqrt(mse_nn)\n",
        "\n",
        "# Calculate the R-squared (R2) score, a measure of how well the model explains the variance in the data.\n",
        "r2_nn = r2_score(y_test, y_pred)\n",
        "# Print the calculated metrics.\n",
        "print(f\"Mean Absolute Error of NN: {mae_nn}\")\n",
        "print(f\"Root Mean Squared Error of NN: {rmse_nn}\")\n",
        "print(f\"R-squared of NN: {r2_nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEKITf2Fjw-1"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(sklearn.__version__)\n",
        "help(mean_squared_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW47guJtvqAW"
      },
      "source": [
        "## Compare Metrics (optional)\n",
        "we compare the performance of NN with baseline linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85GnzAS6oNyW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "results = pd.DataFrame([\n",
        "    {'Model': 'Linear Regression', 'RMSE': rmse_lr, 'MAE': mae_lr, 'R2': r2_lr},\n",
        "    {'Model': 'Neural Net', 'RMSE': rmse_nn, 'MAE': mae_nn, 'R2': r2_nn},\n",
        "])\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qoKc7fHgOBe"
      },
      "outputs": [],
      "source": [
        "# Bar chart of RMSE\n",
        "plt.figure()\n",
        "plt.bar(results['Model'], results['RMSE'])\n",
        "plt.ylabel('RMSE')\n",
        "plt.title('RMSE Comparison')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2s8moatbDE0"
      },
      "source": [
        "# **Task 2: Practical NN training techniques**\n",
        "The task will illustrate some useful NN training techniques, including saving and loading the trained model, using the callback function to save the best model, and adding dropout layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ypA1w6u0Xm9m",
        "outputId": "2666834a-a26a-4107-e3ca-3af409973f1b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 11, but received input with shape (None, 12)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 12), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1750901396.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Train the model using the fit method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mhist_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 11, but received input with shape (None, 12)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 12), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ],
      "source": [
        "from json import load\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "#-------------------------------------------------data preprocessing------------------------------------------------------------------\n",
        "\n",
        "\n",
        "#-------------------------------------------------network construction-----------------------------------------------------------------\n",
        "\n",
        "#************************************************Here you can choose to add the dropout layer or not***************************\n",
        "# #\n",
        "# def construct_network_model():\n",
        "#   # Create a Sequential model, which is a linear stack of layers.\n",
        "#   model = Sequential()\n",
        "\n",
        "#   # Add a Dense layer with 32 units, ReLU activation, and an input dimension of 4.\n",
        "#   model.add(Dense(32, activation='relu', input_dim=4))\n",
        "\n",
        "#   # # Add a Dropout layer with a dropout rate of 0.5.\n",
        "#   # model.add(Dropout(0.5))\n",
        "\n",
        "#   # Add another Dense layer with 64 units and ReLU activation.\n",
        "#   model.add(Dense(64, activation='relu'))\n",
        "\n",
        "#   # # Add another Dropout layer with a dropout rate of 0.5.\n",
        "#   # model.add(Dropout(0.5))\n",
        "\n",
        "#   # Add a final Dense layer with 1 unit (typically used for regression tasks).\n",
        "#   model.add(Dense(1))\n",
        "#   return model\n",
        "\n",
        "# model=construct_network_model()\n",
        "# # Compile the model with the Adam optimizer, Mean Absolute Error (MAE) loss function,\n",
        "# # and MAE metric to be used during training.\n",
        "# model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "#************************************************Here you can choose to add the dropout layer or not*****************\n",
        "\n",
        "#-------------------------------------------------model train------------------------------------------------------------------\n",
        "# use the callback function to early stop, learning rate ajusting, save the best model\n",
        "# Create an EarlyStopping callback to monitor the validation mean absolute error (val_mae).\n",
        "# It will stop training if val_mae doesn't improve for 5 consecutive epochs and restores the best weights.\n",
        "early_stop = EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Create a ReduceLROnPlateau callback to monitor val_mae.\n",
        "# It reduces the learning rate by a factor of 0.5 if val_mae doesn't improve for 3 consecutive epochs.\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=3)\n",
        "\n",
        "# Define the file path where the best model will be saved.\n",
        "filepath = \"weights.best.keras\"\n",
        "\n",
        "# Create a ModelCheckpoint callback to monitor the validation mae (val_mae).\n",
        "# The callback will save thhe model's weights only if the validation mae improves.\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# Train the model using the fit method.\n",
        "hist_2 = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stop, reduce_lr,checkpoint],verbose=0)\n",
        "\n",
        "\n",
        "#-------------------------------------------------model evaluation--------------------------------------------------------------------\n",
        "\n",
        "# Set the style of the plots using Seaborn.\n",
        "sns.set()\n",
        "\n",
        "# Extract the training and validation Mean Absolute Error (MAE) from the training history.\n",
        "err = hist_2.history['mae']\n",
        "val_err = hist_2.history['val_mae']\n",
        "\n",
        "# Define the number of epochs.\n",
        "epochs = range(1, len(err) + 1)\n",
        "\n",
        "# Plot the Training MAE and Validation MAE over epochs.\n",
        "plt.plot(epochs, err, '-', label='Training MAE')\n",
        "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
        "plt.title('Training and Validation MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.legend(loc='upper right')\n",
        "plt.plot()\n",
        "\n",
        "# Use the trained model to predict on the test data.\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) for the predictions.\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('--------------------------------------'+'this is result of the trained model'+\"---------------------------------------------\")\n",
        "# Print the calculated metrics.\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "#-------------------------------------------------load model and evaluation--------------------------------------------------------------------\n",
        "if not filepath ==\"\":\n",
        "  # Load a pre-trained model from the specified file path.\n",
        "  model = load_model(filepath)\n",
        "\n",
        "  # Use the loaded model to predict on the test data.\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "  # Calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) for the predictions.\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  print('--------------------------------------'+'this is result of the model loaded from the local path'+\"---------------------------------------------\")\n",
        "\n",
        "  # Print the calculated metrics.\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"R-squared: {r2}\")\n",
        "\n",
        "\n",
        "\n",
        "  # Create a scatter plot to visualize the relationship\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(y_test, y_pred, alpha=0.5)  # Plot actual vs. predicted values\n",
        "\n",
        "  # Add labels and title\n",
        "  plt.xlabel(\"Actual Values\")\n",
        "  plt.ylabel(\"Predicted Values\")\n",
        "  plt.title(\"Actual vs. Predicted Values\")\n",
        "\n",
        "  # Add a diagonal line for reference (perfect predictions)\n",
        "  plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr1eM98PPpeW"
      },
      "source": [
        "# **Task 3: Compare the results with a linear regression model**\n",
        "The task involves comparing the results obtained from the neural network with those from the linear regression model, and we should analyze the reasons behind any differences in the outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "okMlrWbJSCew",
        "outputId": "016687fb-112d-4812-c0be-9b531d3311b4"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (32, 11)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 11), dtype=float32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3963802624.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Use the trained model to predict on the test data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) for the predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (32, 11)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 11), dtype=float32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Set the style of the plots using seaborn.\n",
        "sns.set()\n",
        "\n",
        "# Use the trained model to predict on the test data.\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) for the predictions.\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('--------------------------------------'+'this is result of the neural network model'+\"---------------------------------------------\")\n",
        "# Print the evaluation metrics.\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model_linear = LinearRegression()\n",
        "model_linear.fit(X_train_scaled, y_train)\n",
        "y_pred_linear = model_linear.predict(X_test_scaled)\n",
        "\n",
        "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
        "# rmse_linear = mean_squared_error(y_test, y_pred_linear, squared=False)\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "print('--------------------------------------'+'this is result of the linear regression model'+\"---------------------------------------------\")\n",
        "print(f\"Mean Absolute Error of linear model: {mae_linear}\")\n",
        "print(f\"Root Mean Squared Error of linear model: {rmse_linear}\")\n",
        "print(f\"R-squared of linear model: {r2_linear}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0voSfClhQ48i"
      },
      "source": [
        "# **Assignment task: Find the best neural network model for the count of rental bikes prediction (assignment submission)**\n",
        "Tuning the neural network models (e.g., dropout, sizing of the network), and finding the best neural network model. Suggestions:\n",
        "- Try adding interaction features (e.g., `hr * workingday`, `weathersit * hum`).\n",
        "- Tune NN hyperparameters (layers, neurons, learning rate) via `GridSearchCV`.\n",
        "- Consider more advanced architectures (e.g., gradient boosting, LSTMs for temporal structure)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oGcXA3loalhv"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}